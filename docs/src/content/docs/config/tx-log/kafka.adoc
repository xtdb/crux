---
title: Kafka
---
:icon: /images/icons
:clojure: /drivers/clojure/configuration#kafka
:kotlin: /drivers/kotlin/kdoc/modules/xtdb-kafka/xtdb.api.log/-kafka/-factory/index.html

https://kafka.apache.org/[Apache Kafka] can be used as an XTDB transaction log.

== Setup

1. Add a dependency to the `com.xtdb/xtdb-kafka` module in your dependency manager.
2. On your Kafka cluster, XTDB requires a Kafka topic to use for its transaction log.
   This can be created manually, or automatically by XTDB (see below).
+
--
* If setting up the topic **manually**, ensure that the topic has:
** **A single partition** - this ensures that the transaction log is strictly ordered.
** `message.timestamp.type` set to `LogAppendTime` - this ensures that the timestamp of the message is the time it was appended to the log, rather than the time it was sent by the producer.
* The XTDB transaction log is generally set up using the default values for configuration. A few other key values to consider:
** `retention.ms`: as messages are not required to be permanently on the transaction log, this value does not need to be particularly high. The default value of **1 day** is sufficient for most use cases. When extra precaution should be taken to prevent any data loss on certain environments, a larger value is recommended, with **1 week** as a starting point.
** `max.message.bytes`: generally, this is using the default value of **1MB**, which is fit for purpose for most transaction log messages. This will depend on the overall size of transactions that are being sent into XTDB.
** `cleanup.policy`: The Kafka module within XTDB does not make use of compacted messages, so it is recommended that the topic cleanup policy should use the default value of **delete**.   
* If allowing XTDB to create the topic **automatically**, ensure that the connection properties supplied to the XTDB node have the appropriate permissions to create topics, and that any non-default topic configuration options are set within the configuration for the module under `topicConfig`.
--
3. XTDB should be configured to use the transaction log topic and the Kafka cluster it is hosted on. It should also be authorised to perform all of the necessary operations on the topic. 
+
--
* For configuring the kafka module to authenticate with the Kafka cluster, the `propertiesFile` or `propertiesMap` configuration options to supply the necessary connection properties. See the <<auth_example,example configuration>> below.
* If using the Kafka cluster is using **ACLs**, ensure that the XTDB node has the following permissions on the transaction log topic:
** `Describe`
** `Read`
** `Write`
-- 

== Configuration

To use the Kafka module, include the following in your node configuration:

[source,yaml]
----
txLog: !Kafka
  # -- required

  # A comma-separated list of host:port pairs to use for establishing the
  # initial connection to the Kafka cluster.
  # (Can be set as an !Env value)
  bootstrapServers: "localhost:9092"

  # Name of the Kafka topic to use for the transaction log.
  # (Can be set as an !Env value)
  topicName: "xtdb-log"

  # -- optional

  # Whether or not to automatically create the topic, if it does not already exist.
  # autoCreateTopic: true

  # The maximum amount of time to block waiting for records to be returned by the Kafka consumer.
  # pollDuration: "PT1S"

  # Path to a Java properties file containing Kafka connection properties,
  # supplied directly to the Kafka client.
  # (Can be set as an !Env value)
  # propertiesFile: "kafka.properties"

  # A map of Kafka connection properties, supplied directly to the Kafka client.
  # propertiesMap:

  # The replication factor of the transaction log topic (if it is automatically created by XTDB).
  # see https://kafka.apache.org/documentation/#replication.factor
  # replicationFactor: 1

  # A map of topic configuration options to use when creating the transaction log topic
  # (if it is automatically created by XTDB).
  # see https://kafka.apache.org/documentation/#topicconfigs
  # topicConfig:
----

[.lang-icons.right]
image:{icon}/clojure.svg[Clojure,link={clojure}]
image:{icon}/kotlin.svg[Kotlin,link={kotlin}]

For examples on how to enable/configure the Kafka module as part of your node, for each client library, see the individual driver documentation:

[#auth_example]
=== SASL Authenticated Kafka Example

The following piece of node configuration demonstrates the following common use case:

* Cluster is secured with SASL - authentication is required from the module.
* Topic has already been created manually.
* Configuration values are being passed in as environment variables.

[source,yaml]
----
txLog: !Kafka
  bootstrapServers: !Env KAFKA_BOOTSTRAP_SERVERS
  topicName: !Env KAFKA_TOPIC_NAME
  autoCreateTopic: false
  propertiesMap:
    sasl.mechanism: PLAIN
    security.protocol: SASL_SSL
    sasl.jaas.config: !Env KAFKA_SASL_JAAS_CONFIG
----

The `KAFKA_SASL_JAAS_CONFIG` environment variable will likely contain a string similar to the following, and should be passed in as a secret value:

[source]
----
org.apache.kafka.common.security.plain.PlainLoginModule required username="username" password="password";
----
